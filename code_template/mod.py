import pandas as pd
import numpy as np
import json
import os
from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, KFold
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.linear_model import LogisticRegression, LinearRegression
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor
from xgboost import XGBClassifier, XGBRegressor
from sklearn.cluster import KMeans
from sklearn.metrics import f1_score, mean_absolute_percentage_error
from sklearn.pipeline import Pipeline
import warnings
import logging
import traceback

warnings.filterwarnings('ignore')

# ---------- Logging Setup ----------
logging.basicConfig(
    filename='modeling_process.log',
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logging.info("Modeling pipeline started.")

try:
    # ---------- Initial Setup ----------
    file_path = '{cleaned_path}'  # (LLM: Replace with actual cleaned file name)
    df = pd.read_csv(file_path)

    output_dir = f'modeling_full_output/{session_id}'
    os.makedirs(output_dir, exist_ok=True)

    # Assume df is pre-loaded with 'target' column
    # === LLM_PROBLEM_FRAMING_CODE_START ===
    # (Remove the following example and replace it with the code generated by LLM)
    # Example:
    # problem_type = 'classification' if df['target'].nunique() <= 10 else 'regression'
    # print(f"Detected problem type: {problem_type}")
    # num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    # cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()
    # X = df.drop(columns=['target'])
    # y = df['target']
    # === LLM_PROBLEM_FRAMING_CODE_END ===

    # (The following is the default problem framing code for the template, if the LLM has generated code, this part can be skipped/replaced)
    target_column = '{target_column}'  # Change placeholder to actual target column
    X = df.drop(columns=[target_column])
    y = df[target_column]

    problem_type = 'classification' if df['target'].nunique() <= 10 else 'regression'
    print(f"Detected problem type: {problem_type}")
    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()

    with open(f'{output_dir}/variable_types.txt', 'w') as f:
        f.write(f"Numeric columns: {num_cols}\nCategorical columns: {cat_cols}\n")

    print("Task 1 complete: Variable types identified.")

    # ---------- Task 2: Clustering ----------
    # === LLM_CLUSTERING_CODE_START ===
    # (Remove the following example and replace it with the code generated by LLM)
    # Example:
    # cluster_data = X.select_dtypes(include=[np.number]).copy()
    # scaler = StandardScaler()
    # cluster_scaled = scaler.fit_transform(cluster_data)
    # inertia = []
    # for k in range(2, 11):
    #     kmeans = KMeans(n_clusters=k, random_state=42).fit(cluster_scaled)
    #     inertia.append(kmeans.inertia_)
    # optimal_k = 2 + np.argmin(np.diff(inertia))
    # kmeans = KMeans(n_clusters=optimal_k, random_state=42).fit(cluster_scaled)
    # X['cluster_label'] = kmeans.labels_
    # X['distance_to_centroid'] = np.min(kmeans.transform(cluster_scaled), axis=1)
    # === LLM_CLUSTERING_CODE_END ===

    # (The following is the default clustering code for the template, if the LLM has generated code, this part can be skipped/replaced)
    cluster_data = X.select_dtypes(include=[np.number]).copy()
    scaler = StandardScaler()
    cluster_scaled = scaler.fit_transform(cluster_data)

    inertia = []
    for k in range(2, 11):
        kmeans = KMeans(n_clusters=k, random_state=42).fit(cluster_scaled)
        inertia.append(kmeans.inertia_)

    optimal_k = 2 + np.argmin(np.diff(inertia))
    kmeans = KMeans(n_clusters=optimal_k, random_state=42).fit(cluster_scaled)
    X['cluster_label'] = kmeans.labels_
    X['distance_to_centroid'] = np.min(kmeans.transform(cluster_scaled), axis=1)

    print(f"Task 2 complete: K={optimal_k} selected, clustering features added.")

    # ---------- Task 3: Model Design ----------
    # === LLM_MODEL_DESIGN_CODE_START ===
    # (Remove the following example and replace it with the code generated by LLM)
    # Example:
    # X_train, X_test, y_train, y_test = train_test_split(
    #     X, y, test_size=0.2, stratify=y if problem_type == 'classification' else None, random_state=42
    # )
    # ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)
    # X_train_enc = pd.DataFrame(ohe.fit_transform(X_train[cat_cols]))
    # X_test_enc = pd.DataFrame(ohe.transform(X_test[cat_cols]))
    # X_train_enc.index, X_test_enc.index = X_train.index, X_test.index
    # X_train_final = pd.concat([X_train[num_cols].reset_index(drop=True), X_train_enc.reset_index(drop=True)], axis=1)
    # X_test_final = pd.concat([X_test[num_cols].reset_index(drop=True), X_test_enc.reset_index(drop=True)], axis=1)
    # === LLM_MODEL_DESIGN_CODE_END ===

    # (The following is the default model design code for the template, if the LLM has generated code, this part can be skipped/replaced)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, stratify=y if problem_type == 'classification' else None, random_state=42
    )
    ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)
    X_train_enc = pd.DataFrame(ohe.fit_transform(X_train[cat_cols]))
    X_test_enc = pd.DataFrame(ohe.transform(X_test[cat_cols]))
    X_train_enc.index, X_test_enc.index = X_train.index, X_test.index
    X_train_final = pd.concat([X_train[num_cols].reset_index(drop=True), X_train_enc.reset_index(drop=True)], axis=1)
    X_test_final = pd.concat([X_test[num_cols].reset_index(drop=True), X_test_enc.reset_index(drop=True)], axis=1)

    print("Task 3 complete: Data split and one-hot encoded.")

    # ---------- Task 4: Model Execution ----------
    # === LLM_MODEL_EXECUTION_CODE_START ===
    # (Remove the following example and replace it with the code generated by LLM)
    # Example:
    # models = {}
    # param_grids = {}
    # if problem_type == 'classification':
    #     models = {
    #         'LogisticRegression': LogisticRegression(max_iter=500),
    #         'RandomForest': RandomForestClassifier(),
    #         'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')
    #     }
    #     param_grids = {
    #         'LogisticRegression': {'C': [0.1, 1, 10]},
    #         'RandomForest': {'n_estimators': [50, 100], 'max_depth': [3, 5]},
    #         'XGBoost': {'n_estimators': [50, 100], 'max_depth': [3, 5]}
    #     }
    #     meta_model = GradientBoostingClassifier()
    # else:
    #     models = {
    #         'LinearRegression': LinearRegression(),
    #         'RandomForest': RandomForestRegressor(),
    #         'XGBoost': XGBRegressor()
    #     }
    #     param_grids = {
    #         'LinearRegression': {},
    #         'RandomForest': {'n_estimators': [50, 100], 'max_depth': [3, 5]},
    #         'XGBoost': {'n_estimators': [50, 100], 'max_depth': [3, 5]}
    #     }
    #     meta_model = GradientBoostingRegressor()
    # best_models = {}
    # for name, model in models.items():
    #     grid = GridSearchCV(model, param_grids.get(name, {}), cv=5)
    #     grid.fit(X_train_final, y_train)
    #     best_models[name] = grid.best_estimator_
    # === LLM_MODEL_EXECUTION_CODE_END ===

    # (The following is the default model execution code for the template, if the LLM has generated code, this part can be skipped/replaced)
    models = {}
    param_grids = {}
    if problem_type == 'classification':
        models = {
            'LogisticRegression': LogisticRegression(max_iter=500),
            'RandomForest': RandomForestClassifier(),
            'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss')
        }
        param_grids = {
            'LogisticRegression': {'C': [0.1, 1, 10]},
            'RandomForest': {'n_estimators': [50, 100], 'max_depth': [3, 5]},
            'XGBoost': {'n_estimators': [50, 100], 'max_depth': [3, 5]}
        }
        meta_model = GradientBoostingClassifier()
    else:
        models = {
            'LinearRegression': LinearRegression(),
            'RandomForest': RandomForestRegressor(),
            'XGBoost': XGBRegressor()
        }
        param_grids = {
            'LinearRegression': {},
            'RandomForest': {'n_estimators': [50, 100], 'max_depth': [3, 5]},
            'XGBoost': {'n_estimators': [50, 100], 'max_depth': [3, 5]}
        }
        meta_model = GradientBoostingRegressor()

    best_models = {}
    for name, model in models.items():
        grid = GridSearchCV(model, param_grids.get(name, {}), cv=5)
        grid.fit(X_train_final, y_train)
        best_models[name] = grid.best_estimator_

    print("Task 4 complete: Base models trained and tuned.")

    # ---------- Ensemble Predictions ----------
    # === LLM_ENSEMBLE_CODE_START ===
    # (Remove the following example and replace it with the code generated by LLM)
    # Example:
    # ensemble_preds = np.mean(
    #     [best_models[name].predict(X_test_final) if problem_type == 'regression'
    #      else best_models[name].predict_proba(X_test_final)[:, 1]
    #      for name in best_models],
    #     axis=0
    # )
    # === LLM_ENSEMBLE_CODE_END ===

    # (The following is the default ensemble code for the template, if the LLM has generated code, this part can be skipped/replaced)
    ensemble_preds = np.mean(
        [best_models[name].predict(X_test_final) if problem_type == 'regression'
        else best_models[name].predict_proba(X_test_final)[:, 1]
        for name in best_models],
        axis=0
    )

    # ---------- Stacked Generalisation ----------
    stacked_train = pd.DataFrame()
    kf = StratifiedKFold(n_splits=5) if problem_type == 'classification' else KFold(n_splits=5)

    for name, model in best_models.items():
        oof_preds = np.zeros(len(X_train_final))
        for train_idx, val_idx in kf.split(X_train_final, y_train):
            model.fit(X_train_final.iloc[train_idx], y_train.iloc[train_idx])
            oof_preds[val_idx] = model.predict(X_train_final.iloc[val_idx])
        stacked_train[name] = oof_preds

    meta_model.fit(stacked_train, y_train)
    stacked_preds = meta_model.predict(X_test_final)

    print("Task 4 complete: Ensemble and stacking completed.")

    # ---------- Task 5: Evaluation ----------
    # === LLM_MODEL_EVAL_CODE_START ===
    # (Remove the following example and replace it with the code generated by LLM)
    # Example:
    # results = {}
    # for name, model in best_models.items():
    #     if problem_type == 'classification':
    #         preds = model.predict(X_test_final)
    #         score = f1_score(y_test, preds, average='micro')
    #     else:
    #         preds = model.predict(X_test_final)
    #         score = 100 * (1 - mean_absolute_percentage_error(y_test, preds))
    #     results[name] = score
    # if problem_type == 'classification':
    #     ensemble_score = f1_score(y_test, (ensemble_preds > 0.5).astype(int), average='micro')
    #     stacked_score = f1_score(y_test, stacked_preds, average='micro')
    # else:
    #     ensemble_score = 100 * (1 - mean_absolute_percentage_error(y_test, ensemble_preds))
    #     stacked_score = 100 * (1 - mean_absolute_percentage_error(y_test, stacked_preds))
    # results['SimpleEnsemble'] = ensemble_score
    # results['StackedModel'] = stacked_score
    # sorted_results = dict(sorted(results.items(), key=lambda item: item[1], reverse=True))
    # print("Leaderboard:")
    # for name, score in sorted_results.items():
    #     print(f"{name}: {score:.4f}")
    # with open(f'{output_dir}/results.json', 'w') as f:
    #     json.dump(sorted_results, f, indent=4)
    # === LLM_MODEL_EVAL_CODE_END ===

    # (The following is the default evaluation code for the template, if the LLM has generated code, this part can be skipped/replaced)
    results = {}
    for name, model in best_models.items():
        if problem_type == 'classification':
            preds = model.predict(X_test_final)
            score = f1_score(y_test, preds, average='micro')
        else:
            preds = model.predict(X_test_final)
            score = 100 * (1 - mean_absolute_percentage_error(y_test, preds))
        results[name] = score

    if problem_type == 'classification':
        ensemble_score = f1_score(y_test, (ensemble_preds > 0.5).astype(int), average='micro')
        stacked_score = f1_score(y_test, stacked_preds, average='micro')
    else:
        ensemble_score = 100 * (1 - mean_absolute_percentage_error(y_test, ensemble_preds))
        stacked_score = 100 * (1 - mean_absolute_percentage_error(y_test, stacked_preds))

    results['SimpleEnsemble'] = ensemble_score
    results['StackedModel'] = stacked_score

    sorted_results = dict(sorted(results.items(), key=lambda item: item[1], reverse=True))
    print("Leaderboard:")
    for name, score in sorted_results.items():
        print(f"{name}: {score:.4f}")

    with open(f'{output_dir}/results.json', 'w') as f:
        json.dump(sorted_results, f, indent=4)

    print("Task 5 complete: Evaluation complete and results saved in JSON.")

    # ---------- Task 6: LLM Interpretation / Summary ----------
    print("""[LLM_MODEL_SUMMARY_PLACEHOLDER]
    Here is the text of the LLM-generated modeling interpretation/summary.
    """)

except Exception as e:
    logging.error(f"An error occurred: {e}")
    logging.error(f"Error details: {traceback.format_exc()}")
    logging.error("Modeling pipeline failed.")
    raise
